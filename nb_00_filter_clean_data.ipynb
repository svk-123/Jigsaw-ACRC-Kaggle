{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f506feee-98f0-4106-a53a-ccbff09b3ce3",
   "metadata": {},
   "source": [
    "# Jigsaw - Agile Community Rules Classification\n",
    "### https://www.kaggle.com/competitions/jigsaw-agile-community-rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9062a4b-55ec-493c-a31e-f03a3489a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 12)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = \"./data/final/\"\n",
    "df_train = pd.read_csv(f\"{base_path}df_train_qkdsr_03.csv\")\n",
    "print(df_train.shape)\n",
    "df=df_train.copy()\n",
    "df_train.head(1)\n",
    "\n",
    "df_clean=pd.read_csv(f\"./data/synthetic_generation/community_rules.csv\")\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "538322d3-4706-4b6d-8a35-692d91b92b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subreddit', 'rule', 'formatted_rule', 'positive_example_1',\n",
       "       'negative_example_1', 'positive_example_2', 'negative_example_2',\n",
       "       'test_comment', 'violates_rule', 'raw_response',\n",
       "       'example_comments_used', 'error'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c8f78ee-e0e7-462f-9a1c-8274fa70c61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['formatted_rule'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90732974-440c-4853-88b3-3050b6555dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"rule\"]=df_clean[\"formatted_rule\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e6e150b-f301-4ab4-a41a-be442554ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_similar_rules_batched(df_train, df_clean, similarity_threshold=0.7, batch_size=1000):\n",
    "#     \"\"\"\n",
    "#     Memory-efficient version for very large datasets\n",
    "#     \"\"\"\n",
    "#     model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "#     # Generate clean embeddings once\n",
    "#     clean_embeddings = model.encode(df_clean['rule'].tolist())\n",
    "    \n",
    "#     filtered_indices = []\n",
    "#     similarities = []\n",
    "    \n",
    "#     # Process train data in batches\n",
    "#     for i in range(0, len(df_train), batch_size):\n",
    "#         batch = df_train.iloc[i:i+batch_size]\n",
    "#         batch_embeddings = model.encode(batch['rule'].tolist())\n",
    "        \n",
    "#         # Compute similarity for this batch\n",
    "#         batch_similarities = cosine_similarity(batch_embeddings, clean_embeddings)\n",
    "#         max_sims = np.max(batch_similarities, axis=1)\n",
    "        \n",
    "#         # Find indices that meet threshold\n",
    "#         valid_batch_indices = np.where(max_sims >= similarity_threshold)[0] + i\n",
    "#         filtered_indices.extend(valid_batch_indices)\n",
    "#         similarities.extend(max_sims[max_sims >= similarity_threshold])\n",
    "        \n",
    "#         print(f\"Processed batch {i//batch_size + 1}/{(len(df_train)-1)//batch_size + 1}\")\n",
    "    \n",
    "#     # Create filtered dataframe\n",
    "#     filtered_df = df_train.iloc[filtered_indices].copy()\n",
    "#     filtered_df['max_similarity'] = similarities\n",
    "    \n",
    "#     return filtered_df\n",
    "\n",
    "# # Usage for large datasets:\n",
    "# # filtered_train = filter_similar_rules_batched(df_train, df_clean, similarity_threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e2be6b4-5730-482e-9930-b21369087df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for clean rules...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf6211ef6784bd1b80caffe0ed765d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for train rules...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61d04acdc4d4352a0bd7a127f6d622b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarity matrix...\n",
      "Original train rules: 5000\n",
      "Filtered train rules: 16\n",
      "Reduction: 99.7%\n",
      "\n",
      "Top 5 most similar matches:\n",
      "                                                   rule  max_similarity  \\\n",
      "5     \"No Medical or Clinical Advice: Do not give or...        0.754827   \n",
      "470   \"No Medical or Clinical Advice: Do not give or...        0.754827   \n",
      "702   \"No Medical or Clinical Advice: Do not give or...        0.754827   \n",
      "1315  \"No Medical or Clinical Advice: Do not give or...        0.754827   \n",
      "1638  \"No Medical or Clinical Advice: Do not give or...        0.754827   \n",
      "\n",
      "                                most_similar_clean_rule  \n",
      "5     no medical advice: do not offer or request spe...  \n",
      "470   no medical advice: do not offer or request spe...  \n",
      "702   no medical advice: do not offer or request spe...  \n",
      "1315  no medical advice: do not offer or request spe...  \n",
      "1638  no medical advice: do not offer or request spe...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def filter_similar_rules(df_train, df_clean, similarity_threshold=0.7, method='sentence_transformer'):\n",
    "    \"\"\"\n",
    "    Filter df_train rules based on similarity to df_clean rules\n",
    "    \n",
    "    Parameters:\n",
    "    - df_train: DataFrame with 'rule' column (30k+ entries)\n",
    "    - df_clean: DataFrame with 'rule' column (200 entries) \n",
    "    - similarity_threshold: float, minimum similarity score to keep (0-1)\n",
    "    - method: 'sentence_transformer' or 'tfidf'\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'sentence_transformer':\n",
    "        # Load pre-trained sentence transformer model\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast and good quality\n",
    "        \n",
    "        # Generate embeddings\n",
    "        print(\"Generating embeddings for clean rules...\")\n",
    "        clean_embeddings = model.encode(df_clean['rule'].tolist(), show_progress_bar=True)\n",
    "        \n",
    "        print(\"Generating embeddings for train rules...\")\n",
    "        train_embeddings = model.encode(df_train['rule'].tolist(), show_progress_bar=True)\n",
    "        \n",
    "    elif method == 'tfidf':\n",
    "        # Alternative: TF-IDF approach (faster but less semantic)\n",
    "        vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "        \n",
    "        # Fit on combined data\n",
    "        all_rules = df_clean['rule'].tolist() + df_train['rule'].tolist()\n",
    "        vectorizer.fit(all_rules)\n",
    "        \n",
    "        clean_embeddings = vectorizer.transform(df_clean['rule'].tolist()).toarray()\n",
    "        train_embeddings = vectorizer.transform(df_train['rule'].tolist()).toarray()\n",
    "    \n",
    "    # Compute similarity matrix (clean_rules vs train_rules)\n",
    "    print(\"Computing similarity matrix...\")\n",
    "    similarity_matrix = cosine_similarity(train_embeddings, clean_embeddings)\n",
    "    \n",
    "    # Get maximum similarity for each train rule\n",
    "    max_similarities = np.max(similarity_matrix, axis=1)\n",
    "    \n",
    "    # Filter based on threshold\n",
    "    similar_mask = max_similarities >= similarity_threshold\n",
    "    filtered_df_train = df_train[similar_mask].copy()\n",
    "    \n",
    "    # Add similarity scores\n",
    "    filtered_df_train['max_similarity'] = max_similarities[similar_mask]\n",
    "    filtered_df_train['most_similar_clean_rule_idx'] = np.argmax(similarity_matrix[similar_mask], axis=1)\n",
    "    \n",
    "    # Add the most similar clean rule for reference\n",
    "    most_similar_clean_rules = df_clean.iloc[filtered_df_train['most_similar_clean_rule_idx']]['rule'].values\n",
    "    filtered_df_train['most_similar_clean_rule'] = most_similar_clean_rules\n",
    "    \n",
    "    print(f\"Original train rules: {len(df_train)}\")\n",
    "    print(f\"Filtered train rules: {len(filtered_df_train)}\")\n",
    "    print(f\"Reduction: {(1 - len(filtered_df_train)/len(df_train))*100:.1f}%\")\n",
    "    \n",
    "    return filtered_df_train, similarity_matrix\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming you have your dataframes ready\n",
    "    # df_train = pd.read_csv('train_data.csv')  # 30k+ rules\n",
    "    # df_clean = pd.read_csv('clean_data.csv')  # 200 rules\n",
    "    \n",
    "    # Method 1: Using Sentence Transformers (recommended for semantic similarity)\n",
    "    filtered_train, sim_matrix = filter_similar_rules(\n",
    "        df_train, \n",
    "        df_clean, \n",
    "        similarity_threshold=0.7,  # Adjust this threshold\n",
    "        method='sentence_transformer'\n",
    "    )\n",
    "    \n",
    "    # Method 2: Using TF-IDF (faster alternative)\n",
    "    # filtered_train, sim_matrix = filter_similar_rules(\n",
    "    #     df_train, \n",
    "    #     df_clean, \n",
    "    #     similarity_threshold=0.3,  # Lower threshold for TF-IDF\n",
    "    #     method='tfidf'\n",
    "    # )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nTop 5 most similar matches:\")\n",
    "    print(filtered_train.nlargest(5, 'max_similarity')[['rule', 'max_similarity', 'most_similar_clean_rule']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "892382a5-2b7a-4e8f-9b2a-f789ae6d1136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 15)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38f4ec59-b837-4184-aad7-82133bb47cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_train.to_csv(\"df_train_f0p6_10k.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7afeb9a-00ba-4329-b05a-87b8a61c3a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train[\"rule\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f467853-f4f1-499f-92fc-5696b149c8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11175052,
     "sourceId": 89659,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.756759,
   "end_time": "2025-02-26T02:09:27.363350",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-26T02:09:20.606591",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
