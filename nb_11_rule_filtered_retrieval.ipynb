{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Rule-Filtered Vector Similarity Retrieval\n",
    "\n",
    "This notebook demonstrates a two-stage retrieval approach:\n",
    "1. **Filter by rule**: Match the query rule to a rule category\n",
    "2. **Retrieve top K**: Get most similar examples from that rule's examples using vector similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.rule_filtered_retrieval import FastEmbedder, RuleFilteredRetriever\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## 2. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 251,740\n",
      "Unique rules: 6\n",
      "\n",
      "Columns: ['rule', 'test_comment', 'violates_rule', 'value']\n",
      "\n",
      "Rule distribution statistics:\n",
      "  Mean examples per rule: 41956.7\n",
      "  Median examples per rule: 45187.5\n",
      "  Min examples per rule: 34585\n",
      "  Max examples per rule: 46215\n",
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "base_path = \"./data/final/zothers/\"\n",
    "df_train = pd.read_csv(f\"{base_path}rule_comment.csv\")\n",
    "df_train['value'] = df_train['value'].replace(0, -1)\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Total training examples: {len(df_train):,}\")\n",
    "print(f\"Unique rules: {df_train['rule'].nunique():,}\")\n",
    "print(f\"\\nColumns: {df_train.columns.tolist()}\")\n",
    "\n",
    "# Show rule distribution\n",
    "rule_counts = df_train['rule'].value_counts()\n",
    "print(f\"\\nRule distribution statistics:\")\n",
    "print(f\"  Mean examples per rule: {rule_counts.mean():.1f}\")\n",
    "print(f\"  Median examples per rule: {rule_counts.median():.1f}\")\n",
    "print(f\"  Min examples per rule: {rule_counts.min()}\")\n",
    "print(f\"  Max examples per rule: {rule_counts.max()}\")\n",
    "\n",
    "df_train.head()\n",
    "print(df_train[\"value\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sample-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 251,739 samples for faster experimentation\n",
      "Unique rules in sample: 6\n"
     ]
    }
   ],
   "source": [
    "# Sample for faster experimentation (optional)\n",
    "SAMPLE_SIZE = 251739 # Set to None to use all data\n",
    "\n",
    "if SAMPLE_SIZE and SAMPLE_SIZE < len(df_train):\n",
    "    df_train_sample = df_train.sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Using {len(df_train_sample):,} samples for faster experimentation\")\n",
    "else:\n",
    "    df_train_sample = df_train\n",
    "    print(f\"Using all {len(df_train_sample):,} examples\")\n",
    "\n",
    "print(f\"Unique rules in sample: {df_train_sample['rule'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-retriever-header",
   "metadata": {},
   "source": [
    "## 3. Initialize Rule-Filtered Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "init-embedder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen3-Embedding model...\n",
      "Embedder initialized on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedder\n",
    "print(\"Loading Qwen3-Embedding model...\")\n",
    "embedder = FastEmbedder(\n",
    "    model_name='Qwen/Qwen3-Embedding-0.6B',\n",
    "    output_dim=1024  # Can experiment with 512, 1024, or full dimension\n",
    ")\n",
    "\n",
    "print(f\"Embedder initialized on device: {embedder.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "build-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing retriever...\n",
      "\n",
      "Building rule-filtered indices...\n",
      "Building rule-filtered index from 251739 examples...\n",
      "Strategy: Filter by rule FIRST, then search by COMMENT similarity only\n",
      "Found 6 unique rules\n",
      "Encoding comments only (not combined with rules)...\n",
      "Building per-rule FAISS indices...\n",
      "  Rule 'No Advertising: Spam, referral links, unsolicited ...' : 34599 examples\n",
      "  Rule 'No legal advice: Do not offer or request legal adv...' : 34585 examples\n",
      "  Rule 'no financial advice: we do not permit comments tha...' : 46215 examples\n",
      "  Rule 'no medical advice: do not offer or request specifi...' : 45965 examples\n",
      "  Rule 'no promotion of illegal activity: do not encourage...' : 45245 examples\n",
      "  Rule 'no spoilers: do not reveal important details that ...' : 45130 examples\n",
      "\n",
      "Index building complete!\n",
      "Total rules: 6\n",
      "Total examples: 251739\n",
      "\n",
      "✓ Index building complete!\n"
     ]
    }
   ],
   "source": [
    "# Initialize retriever and build index\n",
    "print(\"Initializing retriever...\")\n",
    "retriever = RuleFilteredRetriever(embedder, use_gpu=True)\n",
    "\n",
    "# Define instruction for better retrieval\n",
    "instruction = \"Given a rule and comment, retrieve similar training examples for classification\"\n",
    "\n",
    "# Build index (this creates separate FAISS index for each rule)\n",
    "print(\"\\nBuilding rule-filtered indices...\")\n",
    "retriever.build_index(\n",
    "    df_train_sample,\n",
    "    rule_col='rule',\n",
    "    comment_col='test_comment',\n",
    "    value_col='value',\n",
    "    instruction=instruction\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Index building complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-single-header",
   "metadata": {},
   "source": [
    "## 4. Test Single Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "test-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Rule: no promotion of illegal activity: do not encourage or promote illegal activities, such as drug-related activity, violence, exploitation, theft, or other criminal behavior....\n",
      "\n",
      "Query Comment: \"Instead of stealing lab supplies, why not check if there are any grants or funding options available? It’s a lot less risky and more ethical.\"...\n",
      "\n",
      "True Value: -1\n",
      "\n",
      "================================================================================\n",
      "RETRIEVAL RESULTS\n",
      "================================================================================\n",
      "Matched Rule Type: exact\n",
      "Number of examples in this rule category: 45245\n",
      "Retrieved: 10 examples\n",
      "\n",
      "Top 5 Similarities:\n",
      "  1. Similarity: 1.0000, Value: -1, Comment: \"Instead of stealing lab supplies, why not check if there are any grants or fund...\n",
      "  2. Similarity: 0.7566, Value: 1, Comment: \"Why not just break into a research lab and steal the equipment? It’s not like t...\n",
      "  3. Similarity: 0.7383, Value: -1, Comment: \"Instead of trying to get funding through illegal means, why not apply for more ...\n",
      "  4. Similarity: 0.7058, Value: -1, Comment: Instead of stealing, why not look for odd jobs or community resources? There are...\n",
      "  5. Similarity: 0.6981, Value: 1, Comment: \"Why not just hack into a lab and steal the materials you need? It’s not like th...\n",
      "\n",
      "Predicted Value: -0.400\n",
      "Predicted Decision: 0\n",
      "True Value: -1\n"
     ]
    }
   ],
   "source": [
    "# Test with a random example\n",
    "test_idx = 42\n",
    "test_row = df_train_sample.iloc[test_idx]\n",
    "\n",
    "print(f\"Query Rule: {test_row['rule'][:200]}...\")\n",
    "print(f\"\\nQuery Comment: {test_row['test_comment'][:200]}...\")\n",
    "print(f\"\\nTrue Value: {test_row['value']}\")\n",
    "\n",
    "# Retrieve similar examples\n",
    "result = retriever.retrieve(\n",
    "    query_rule=test_row['rule'],\n",
    "    query_comment=test_row['test_comment'],\n",
    "    top_k=10,\n",
    "    instruction=instruction\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RETRIEVAL RESULTS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Matched Rule Type: {result['rule_match_type']}\")\n",
    "print(f\"Number of examples in this rule category: {result['num_examples_in_rule']}\")\n",
    "print(f\"Retrieved: {len(result['examples'])} examples\")\n",
    "\n",
    "print(f\"\\nTop 5 Similarities:\")\n",
    "for i, (sim, ex) in enumerate(zip(result['similarities'][:5], result['examples'][:5])):\n",
    "    print(f\"  {i+1}. Similarity: {sim:.4f}, Value: {ex['value']}, Comment: {ex['test_comment'][:80]}...\")\n",
    "\n",
    "# Calculate prediction\n",
    "retrieved_values = [ex['value'] for ex in result['examples']]\n",
    "predicted_value = np.mean(retrieved_values)\n",
    "predicted_decision = 1 if predicted_value > 0 else 0\n",
    "\n",
    "print(f\"\\nPredicted Value: {predicted_value:.3f}\")\n",
    "print(f\"Predicted Decision: {predicted_decision}\")\n",
    "print(f\"True Value: {test_row['value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-eval-header",
   "metadata": {},
   "source": [
    "## 5. Batch Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "load-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 2,000\n",
      "Unique rules in test: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rule</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>test_comment</th>\n",
       "      <th>violates_rule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personalfinance</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Hey everyone, I've been using Wealthfront for ...</td>\n",
       "      <td>I've had good luck with Vanguard index funds f...</td>\n",
       "      <td>As a certified financial planner, I'm offering...</td>\n",
       "      <td>When my emergency fund hit $10k I moved it to ...</td>\n",
       "      <td>I work for Acme Investing and we're running a ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tifu</td>\n",
       "      <td>no promotion of illegal activity: do not encou...</td>\n",
       "      <td>Just go back after hours and jimmy the window ...</td>\n",
       "      <td>My friend once accidentally set off the fire a...</td>\n",
       "      <td>Honestly dude just lace their drinks with some...</td>\n",
       "      <td>I can't believe I told my boss \"love you\" inst...</td>\n",
       "      <td>Next time they pull that shit, just slash thei...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OutOfTheLoop</td>\n",
       "      <td>no promotion of illegal activity: do not encou...</td>\n",
       "      <td>Just torrent the movie bro, studios make enoug...</td>\n",
       "      <td>Some people use VPNs to access geo-restricted ...</td>\n",
       "      <td>If your landlord is screwing you over, just st...</td>\n",
       "      <td>There are legitimate ways to protest unfair po...</td>\n",
       "      <td>Honestly if someone steals from you, just brea...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nottheonion</td>\n",
       "      <td>no medical advice: do not offer or request spe...</td>\n",
       "      <td>For that persistent cough you mentioned, you s...</td>\n",
       "      <td>Wow this article about hospitals using leeches...</td>\n",
       "      <td>OP if you're experiencing those symptoms, stop...</td>\n",
       "      <td>Reading this makes me want to schedule my annu...</td>\n",
       "      <td>If your headache lasts more than 2 days, you p...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christianity</td>\n",
       "      <td>no medical advice: do not offer or request spe...</td>\n",
       "      <td>Hey guys I've been having these intense migrai...</td>\n",
       "      <td>Praying for everyone struggling with health is...</td>\n",
       "      <td>My anxiety is through the roof lately and my Z...</td>\n",
       "      <td>Has anyone found comfort in specific Psalms du...</td>\n",
       "      <td>My daughter has a 102 fever that won't break w...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                               rule  \\\n",
       "0  personalfinance  No Advertising: Spam, referral links, unsolici...   \n",
       "1             tifu  no promotion of illegal activity: do not encou...   \n",
       "2     OutOfTheLoop  no promotion of illegal activity: do not encou...   \n",
       "3      nottheonion  no medical advice: do not offer or request spe...   \n",
       "4     Christianity  no medical advice: do not offer or request spe...   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  Hey everyone, I've been using Wealthfront for ...   \n",
       "1  Just go back after hours and jimmy the window ...   \n",
       "2  Just torrent the movie bro, studios make enoug...   \n",
       "3  For that persistent cough you mentioned, you s...   \n",
       "4  Hey guys I've been having these intense migrai...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  I've had good luck with Vanguard index funds f...   \n",
       "1  My friend once accidentally set off the fire a...   \n",
       "2  Some people use VPNs to access geo-restricted ...   \n",
       "3  Wow this article about hospitals using leeches...   \n",
       "4  Praying for everyone struggling with health is...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  As a certified financial planner, I'm offering...   \n",
       "1  Honestly dude just lace their drinks with some...   \n",
       "2  If your landlord is screwing you over, just st...   \n",
       "3  OP if you're experiencing those symptoms, stop...   \n",
       "4  My anxiety is through the roof lately and my Z...   \n",
       "\n",
       "                                  negative_example_2  \\\n",
       "0  When my emergency fund hit $10k I moved it to ...   \n",
       "1  I can't believe I told my boss \"love you\" inst...   \n",
       "2  There are legitimate ways to protest unfair po...   \n",
       "3  Reading this makes me want to schedule my annu...   \n",
       "4  Has anyone found comfort in specific Psalms du...   \n",
       "\n",
       "                                        test_comment violates_rule  \n",
       "0  I work for Acme Investing and we're running a ...           Yes  \n",
       "1  Next time they pull that shit, just slash thei...           Yes  \n",
       "2  Honestly if someone steals from you, just brea...           Yes  \n",
       "3  If your headache lasts more than 2 days, you p...           Yes  \n",
       "4  My daughter has a 102 fever that won't break w...           Yes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "df_test = pd.read_csv(\"./data/final/df_test_cr_12.csv\")\n",
    "\n",
    "print(f\"Test set size: {len(df_test):,}\")\n",
    "print(f\"Unique rules in test: {df_test['rule'].nunique():,}\")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "batch-retrieve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating with top_k=10...\n",
      "  F1-Score: 0.9861\n",
      "  Rule match types:\n",
      "rule_match_type\n",
      "exact    2000\n",
      "\n",
      "✓ Batch evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# Batch retrieval with different top_k values\n",
    "TOP_K_VALUES = [10]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for top_k in TOP_K_VALUES:\n",
    "    print(f\"\\nEvaluating with top_k={top_k}...\")\n",
    "    \n",
    "    results_df = retriever.batch_retrieve(\n",
    "        df_test,\n",
    "        rule_col='rule',\n",
    "        comment_col='test_comment',\n",
    "        top_k=top_k,\n",
    "        instruction=instruction\n",
    "    )\n",
    "    \n",
    "    results_dict[top_k] = results_df\n",
    "    \n",
    "    # Calculate metrics\n",
    "    y_true = df_test[\"violates_rule\"].astype(str).str.strip().str.strip('\"').str.strip(\"'\").str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "    y_pred = results_df[\"decision\"].values\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    print(f\"  Rule match types:\")\n",
    "    print(results_df['rule_match_type'].value_counts().to_string())\n",
    "\n",
    "print(\"\\n✓ Batch evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-header",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "analyze-best",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (top_k=10):\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Violation       0.99      0.98      0.99      1000\n",
      "   Violation       0.98      0.99      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "================================================================================\n",
      "                    Predicted No    Predicted Yes\n",
      "Actual No                    981               19\n",
      "Actual Yes                     9              991\n",
      "================================================================================\n",
      "\n",
      "Detailed Metrics:\n",
      "  Accuracy:  0.9860\n",
      "  Precision: 0.9812\n",
      "  Recall:    0.9910\n",
      "  F1-Score:  0.9861\n"
     ]
    }
   ],
   "source": [
    "# Choose best performing top_k\n",
    "best_k = 10\n",
    "results_df = results_dict[best_k]\n",
    "\n",
    "# Prepare ground truth\n",
    "y_true = df_test[\"violates_rule\"].astype(str).str.strip().str.strip('\"').str.strip(\"'\").str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "y_pred = results_df[\"decision\"].values\n",
    "\n",
    "# Classification report\n",
    "print(f\"Classification Report (top_k={best_k}):\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_true, y_pred, target_names=['No Violation', 'Violation']))\n",
    "\n",
    "# Text-based confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"                    Predicted No    Predicted Yes\")\n",
    "print(f\"Actual No           {cm[0,0]:>12}    {cm[0,1]:>13}\")\n",
    "print(f\"Actual Yes          {cm[1,0]:>12}    {cm[1,1]:>13}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Additional metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"\\nDetailed Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"  F1-Score:  {f1_score(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compare-topk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison Across Different Top-K Values:\n",
      "================================================================================\n",
      " top_k  f1_score  precision  recall  accuracy\n",
      "    10   0.98607   0.981188   0.991     0.986\n",
      "================================================================================\n",
      "\n",
      "Best performing configuration:\n",
      "  Top-K: 10\n",
      "  F1-Score: 0.9861\n",
      "  Precision: 0.9812\n",
      "  Recall: 0.9910\n",
      "  Accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "# Compare different top_k values\n",
    "comparison_data = []\n",
    "\n",
    "for top_k, results_df in results_dict.items():\n",
    "    y_true = df_test[\"violates_rule\"].astype(str).str.strip().str.strip('\"').str.strip(\"'\").str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "    y_pred = results_df[\"decision\"].values\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'top_k': top_k,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'accuracy': accuracy_score(y_true, y_pred)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Performance Comparison Across Different Top-K Values:\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show best performing top_k\n",
    "best_row = comparison_df.loc[comparison_df['f1_score'].idxmax()]\n",
    "print(f\"\\nBest performing configuration:\")\n",
    "print(f\"  Top-K: {int(best_row['top_k'])}\")\n",
    "print(f\"  F1-Score: {best_row['f1_score']:.4f}\")\n",
    "print(f\"  Precision: {best_row['precision']:.4f}\")\n",
    "print(f\"  Recall: {best_row['recall']:.4f}\")\n",
    "print(f\"  Accuracy: {best_row['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 7. Save/Load Index for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "save-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to ./saved_indices/rule_filtered_sample...\n",
      "Saving index to ./saved_indices/rule_filtered_sample...\n",
      "✓ Index saved successfully!\n",
      "  - 6 FAISS indices\n",
      "  - 251739 training examples\n",
      "  - Embeddings shape: (251739, 1024)\n",
      "\n",
      "✓ Index saved! You can now load it later without rebuilding.\n",
      "  Files saved in: ./saved_indices/rule_filtered_sample\n",
      "\n",
      "To use it later:\n",
      "  1. Initialize embedder and retriever\n",
      "  2. Call: retriever.load_index(save_dir)\n",
      "  3. Use retriever.retrieve() or retriever.batch_retrieve()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTION 1: Save the index for later use\n",
    "# ============================================================================\n",
    "\n",
    "# Save the built index\n",
    "save_dir = \"./saved_indices/rule_filtered_sample\"\n",
    "print(f\"Saving index to {save_dir}...\")\n",
    "retriever.save_index(save_dir)\n",
    "\n",
    "print(\"\\n✓ Index saved! You can now load it later without rebuilding.\")\n",
    "print(f\"  Files saved in: {save_dir}\")\n",
    "print(\"\\nTo use it later:\")\n",
    "print(\"  1. Initialize embedder and retriever\")\n",
    "print(\"  2. Call: retriever.load_index(save_dir)\")\n",
    "print(\"  3. Use retriever.retrieve() or retriever.batch_retrieve()\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
